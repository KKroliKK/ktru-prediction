# Иерархическое предсказание КТРУ кода

### Задачу предсказазания КТРУ кода можно представить в виде задачи иерархической классификации.

Вот пример категории кода КТРУ:

**22.29.25.000-00000011 - Папка пластиковая**

Каждые несколько цифр, разделенных точками и дефисом представляют собой путь по дереву категорий.

Так:

22 - это [Изделия резиновые и пластмассовые](https://snab.kontur.ru/classifiers/okpd2/22?text=22)

22.29 - [Изделия пластмассовые прочие](https://snab.kontur.ru/classifiers/okpd2/22.29?text=22.29)

22.29.25 - [Принадлежности канцелярские или школьные пластмассовые](https://snab.kontur.ru/classifiers/okpd2/22.29.25?text=22.29.25)

22.29.25.000 - [Принадлежности канцелярские или школьные пластмассовые](https://snab.kontur.ru/classifiers/okpd2/22.29.25.000?text=22.29.25.000)

22.29.25.000-00000011 - [Папка пластиковая](https://snab.kontur.ru/classifiers/ktru/22.29.25.000-00000011)

### Основной целью тренировки моделей машинного обучения является выяление скрытого паттерна в данных, аппроксимация истинной зависимости.

В основу модели легла гипотеза о том, что если разделить работу по предсказанию между несколькими моделями, то итоговая система хорошо покажет себя в подобной иерархической классификации.

Модель имеет следущую архитектуру: 

[https://miro.com/app/board/uXjVPEn1EMY=/?share_link_id=238605818262](https://miro.com/app/board/uXjVPEn1EMY=/?share_link_id=238605818262)

Первой “корневой” модели нужно всего лишь научиться различать большие категории товаров. Например, отличать **Изделия резиновые и пластмассовые** **(код 22)** от **Бумаги и изделий бумажных (код 17).** Если корневая модель предсказала категорию 22, то дальше она делигирует работу модели, которая училась различать подкатегории 22, такие как 22.19, 22.21 и так далее. Эта модель училась разделять изделия резиновые от пластмассовых. Предсказание продолжается по частям, пока не будет предсказан весь код целиком.

Гипотеза о том, что если распределить работу по предсказанию кода между несколькими моделями, то каждой из них будет более легкий паттерн, который нужно выучить и они с этим хорошо справятся.

Преимущством также является возможость легкого внесения изменений в структуру дерева категорий. При добавлении новых категорий не нужно будет переобучать весь классификатор, а только ветку дерева, котрую затронули изменения.

### Технические детали:

Итоговый клссификатор представляет собой дерево глубиной в 5. Каждый узел дерева представляет собой однослойную полносвязную нейронную сеть с батч-нормализацией. Размер скрытого слоя - 100 нейронов. Функция активации - ReLU.

На вход модели подаются название и описание товара, затем они разделяются на токены. По токенизированным названию и описанию берутся обученные эмбеддинги fasttext, затем берется среднее арифмитическое по полученным эмбеддингам. Усредненные эмбеддинги соединяются по второй размерности и подаются на вход корневой модели.

Модель показывает accuracy 95% на тестовой выборке.
